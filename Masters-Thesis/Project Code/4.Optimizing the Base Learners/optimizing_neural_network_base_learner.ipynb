{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "optimizing_neural_network_base_learner.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "8XL7qmi5ZcOj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install hyperas\n",
        "!pip install hyperopt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Q5amlRHZRXm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from hyperopt import Trials, STATUS_OK, tpe\n",
        "from hyperas import optim\n",
        "from hyperas.distributions import choice, uniform"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZvbJZ1svcoqS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from keras.utils import to_categorical\n",
        "from sklearn.preprocessing import LabelEncoder, MinMaxScaler, RobustScaler, PowerTransformer\n",
        "from sklearn import preprocessing\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from collections import Counter\n",
        "from keras.models import Sequential\n",
        "import time\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import Activation\n",
        "from sklearn.utils import class_weight\n",
        "from keras import utils as cat_utils\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DNUcc92HtL4C",
        "colab_type": "text"
      },
      "source": [
        "**Fetching data for base learner optimization**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PYftXxNBcqP2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_git = 'https://raw.githubusercontent.com/rohandongare-nci/18120199-Data/master/Base%20Learner%20Optimization/Base%20Learners%20Optimization.csv'\n",
        "sdss_1 = pd.read_csv(data_git)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_etJ3sYZCp3w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sdss_opt=sdss_1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y57n0BFRCtaJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sdss_opt.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wb23-hXycwwO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "unwanted_columns = ['camcol','run','rerun','objid','specobjid']\n",
        "sdss_opt.drop(unwanted_columns, axis=1, inplace=True)\n",
        "sdss_opt.head(10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yvP_O797cylv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
        "enc = LabelEncoder()\n",
        "X_opt = sdss_opt[['ra','dec','u','g','r','i','z','redshift','plate','mjd','fiberid','field']]\n",
        "y_opt = enc.fit_transform(sdss_opt['class'])\n",
        "X_opt.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sA8G3YKYjwX3",
        "colab_type": "text"
      },
      "source": [
        "**Normalization and Transformation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j4BOcZwRkrvL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_opt = preprocessing.normalize(X_opt, norm='l2')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Au41CuxKjnGz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transform_opt = preprocessing.PowerTransformer(method='yeo-johnson', standardize=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fyiYXrkRl4k0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_opt = transform_opt.fit_transform(X_opt)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pD1f3frEmSDp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(X_opt)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mMqtBJ0RmkxQ",
        "colab_type": "text"
      },
      "source": [
        "**Two approaches towards optimizing Neural Networks, one with weights and other with undersampling**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SGrpIqGJni_3",
        "colab_type": "text"
      },
      "source": [
        "**using weights**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4eaMRfWltphi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sdss_weights=class_weight.compute_class_weight('balanced',np.unique(y),y)\n",
        "print(y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aQU36YIpnqkJ",
        "colab_type": "text"
      },
      "source": [
        "**Undersampling the majority class**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQ7t97TGnx1U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Counter(y_opt)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rZY-d1Otp8IT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "under_sampler_opt = RandomUnderSampler(random_state=18120199,replacement=False)\n",
        "X_undersam, y_undersam = under_sampler_opt.fit_resample(X_opt, y_opt)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5jPcECE0s0Gy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Counter(y_undersam)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OtYLZzbVc56t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_undersam = to_categorical(y_undersam)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H5sWJb3Lc-zm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_val, Y_train, Y_val = train_test_split(X_undersam, y_undersam, test_size = 0.2, random_state = 18120199)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3C1JheDlyLu1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(X_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yzS5s_beiSQq",
        "colab_type": "text"
      },
      "source": [
        "**Neural Network Optimization**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "63kgkZuTrl9Z",
        "colab_type": "text"
      },
      "source": [
        "**Hyperopt requires a separate function defined for fetching data, any value outside of the function is not recognized**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cfCSJ3yoq1xT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def under_data():\n",
        "    import keras\n",
        "    from keras import utils as cat_utils\n",
        "    from sklearn.preprocessing import LabelEncoder, PowerTransformer\n",
        "    from keras.models import Sequential\n",
        "    import time\n",
        "    from keras.layers import Dense\n",
        "    from keras.layers import Dropout\n",
        "    from keras.layers import Activation\n",
        "    #fetching raw data from my own repository\n",
        "    data_git = 'https://raw.githubusercontent.com/rohandongare-nci/'\\\n",
        "    '18120199-Data/master/Base%20Learner%20Optimization/Base%20Learners%20Optimization.csv'\n",
        "    sdss_opt_nn = pd.read_csv(data_git)\n",
        "    unwanted_columns = ['camcol','run','rerun','objid','specobjid']\n",
        "    sdss_opt_nn.drop(unwanted_columns, axis=1, inplace=True)\n",
        "    enc = LabelEncoder()\n",
        "    X_opt_nn = sdss_opt_nn[['ra','dec','u','g','r','i','z','redshift','plate','mjd','fiberid','field']]\n",
        "    y_opt_nn = enc.fit_transform(sdss_opt_nn['class'])\n",
        "    #normalizing the data\n",
        "    X_opt_nn = preprocessing.normalize(X_opt_nn, norm='l2')\n",
        "    #transforming the data using yeo-johnson transformer\n",
        "    transform_opt = preprocessing.PowerTransformer(method='yeo-johnson', standardize=True)\n",
        "    X_opt_nn = transform_opt.fit_transform(X_opt_nn)\n",
        "    under_sampler_opt = RandomUnderSampler(random_state=18120199,replacement=False)\n",
        "    X_undersam_nn, y_undersam_nn = under_sampler_opt.fit_resample(X_opt_nn, y_opt_nn)\n",
        "    #onehot encoding the target variable\n",
        "    y_undersam_nn = cat_utils.to_categorical(y_undersam_nn, 3)\n",
        "    xtrain, xval, ytrain, yval = train_test_split(X_undersam_nn,y_undersam_nn,test_size=0.2, random_state=18120199)\n",
        "    return xtrain, ytrain, xval, yval"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-bda39u674ox",
        "colab_type": "text"
      },
      "source": [
        "**Function to define NN model** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IItvGkEsdHnx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model_opt(xtrain, ytrain, xval, yval):\n",
        "    model_sdss_opt = Sequential()\n",
        "    #defining search space for number of neurons\n",
        "    model_sdss_opt.add(Dense({{choice([64,128,256,512,1024])}}, input_shape=(12,)))\n",
        "    #defining search space for the activation function using the choice function\n",
        "    model_sdss_opt.add(Activation({{choice(['relu','tanh','sigmoid'])}}))\n",
        "    #defining search space for dropout regularization\n",
        "    model_sdss_opt.add(Dropout({{uniform(0, 1)}}))\n",
        "    #similarly defining search space for layer 2,3,4\n",
        "    model_sdss_opt.add(Dense({{choice([64,128,256,512,1024])}}))\n",
        "    model_sdss_opt.add(Activation({{choice(['relu','tanh','sigmoid'])}}))\n",
        "    model_sdss_opt.add(Dropout({{uniform(0, 1)}}))\n",
        "    model_sdss_opt.add(Dense({{choice([64,128,256,512,1024])}}))\n",
        "    model_sdss_opt.add(Activation({{choice(['relu','tanh','sigmoid'])}}))\n",
        "    model_sdss_opt.add(Dropout({{uniform(0, 1)}}))\n",
        "    model_sdss_opt.add(Dense({{choice([64,128,256,512,1024])}}))\n",
        "    model_sdss_opt.add(Activation({{choice(['relu','tanh','sigmoid'])}}))\n",
        "    model_sdss_opt.add(Dropout({{uniform(0, 1)}}))\n",
        "    #checking if an additional layer will lead to a better performance\n",
        "    if {{choice(['four', 'five'])}} == 'five':\n",
        "        model_sdss_opt.add(Dense({{choice([64,128,256,512,1024])}}))\n",
        "        model_sdss_opt.add(Activation({{choice(['relu', 'sigmoid','tanh'])}}))\n",
        "        model_sdss_opt.add(Dropout({{uniform(0, 1)}}))\n",
        "    model_sdss_opt.add(Dense(3))\n",
        "    model_sdss_opt.add(Activation('softmax'))\n",
        "    adam_opt = keras.optimizers.Adam(lr={{choice([10**-4, 10**-3, 10**-2])}})\n",
        "    model_sdss_opt.compile(loss='categorical_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])\n",
        "    model_sdss_opt.fit(xtrain, ytrain,\n",
        "              batch_size={{choice([150,300])}},\n",
        "              nb_epoch=1,\n",
        "              verbose=1,\n",
        "              validation_data=(xval, yval))\n",
        "    eval_score, model_acc = model_sdss_opt.evaluate(xval, yval, verbose=1)\n",
        "    print('test accuracy acheived:', model_acc)\n",
        "    return {'loss': -model_acc, 'status': STATUS_OK, 'model': model_sdss_opt}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3x66RxFg2dAN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xtrain, ytrain, xval, yval = under_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V378YzhrdOXh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "start_nn=time.time()\n",
        "best_nn_run, best_nn_model = optim.minimize(model=model_opt,\n",
        "                                      data=under_data,\n",
        "                                      algo=tpe.suggest,\n",
        "                                      max_evals=30,\n",
        "                                      trials=Trials(),\n",
        "                                      notebook_name='optimizing_neural_network_base_learner')\n",
        "end_nn=time.time()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y-Ey0kBc4APm",
        "colab_type": "text"
      },
      "source": [
        "**Uploading this notebook on google cloud as it is requirement of hyperas**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "76inDDWu34EO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "537xtyYW37tx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mur7JuKP5FlM",
        "colab_type": "text"
      },
      "source": [
        "**Best run hyperparameters**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SxVl7RM25JAS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(best_nn_run)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}